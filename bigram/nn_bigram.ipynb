{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\Desktop\\lms\n"
     ]
    }
   ],
   "source": [
    "if not \"working_directory_corrected\" in vars():\n",
    "    %cd ..\n",
    "    working_directory_corrected = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Bigrams\n",
    "- same approach as with the pure bigram model based on the probabilities of the data set, this time with a neural net with gradient based optimization\n",
    "- idea is to predict a probability distribution based on the last character to find the new character\n",
    "- the model is trained on list of names with the average negative log likelihood loss function established in the previous bigram model\n",
    "- the label for each data point will be the next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = open(\"data/names.txt\").read().splitlines()\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [\".\"] + sorted(list(set(\"\".join(names))))\n",
    "char2idx = {c: i for i, c in enumerate(chars)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n"
     ]
    }
   ],
   "source": [
    "# training set\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "for name in names[:1]:\n",
    "    chrs = [\".\"] + list(name) + [\".\"]\n",
    "    for ch1, ch2 in zip(chrs, chrs[1:]):\n",
    "        idx1 = char2idx[ch1]\n",
    "        idx2 = char2idx[ch2]\n",
    "        print(ch1, ch2)\n",
    "        xs.append(idx1)\n",
    "        ys.append(idx2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 13, 13,  1]), tensor([ 5, 13, 13,  1,  0]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc = F.one_hot(xs, num_classes=27).float() # casting to float so nn can work with it\n",
    "x_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18e12d66a70>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[-1.0233],\n",
       "         [ 0.6966],\n",
       "         [ 0.2599],\n",
       "         [-0.6688],\n",
       "         [ 0.5313],\n",
       "         [ 1.4865],\n",
       "         [ 1.6403],\n",
       "         [ 0.3220],\n",
       "         [-1.1828],\n",
       "         [-1.4430],\n",
       "         [ 0.8453],\n",
       "         [ 0.9677],\n",
       "         [-1.3930],\n",
       "         [ 0.3996],\n",
       "         [ 1.7170],\n",
       "         [-0.1110],\n",
       "         [ 0.0720],\n",
       "         [-1.3346],\n",
       "         [-0.1574],\n",
       "         [-0.6806],\n",
       "         [ 1.0903],\n",
       "         [-1.8742],\n",
       "         [-0.1673],\n",
       "         [-1.0986],\n",
       "         [ 0.0215],\n",
       "         [ 0.3334],\n",
       "         [-0.5983]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc, torch.randn((27, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3634],\n",
       "        [ 1.5080],\n",
       "        [ 0.3771],\n",
       "        [ 0.3771],\n",
       "        [ 0.6264]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing weights\n",
    "# doing matrix multiplication with the encoded x's (batch of multiple)\n",
    "# this will feed in all x's into every neuron at the same time, pytorch can do this in parallel\n",
    "\n",
    "# x_enc (5, 27) @ weights (27, 1) -> (5, 1)\n",
    "\n",
    "W = torch.randn((27, 1)) # -> one neuron, 27 inputs, one for each possible character\n",
    "x_enc @ W # returns (5, 1) for 5 input x's, one activation which is dot product between the encoded x and the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8228, -0.9996,  1.9027, -0.4031, -0.7423,  1.4252, -0.5842, -0.4163,\n",
       "          1.5283, -0.2163, -0.1250, -1.5076,  1.6666, -1.6918,  1.8165,  1.5119,\n",
       "          0.3403,  0.7355, -0.2298, -0.0905, -1.5814, -0.8590,  2.0835,  3.0896,\n",
       "          0.3318, -0.4650, -0.2678],\n",
       "        [ 0.8312, -0.9745,  1.1119, -0.5773,  0.5229,  0.5173,  0.2952, -0.3793,\n",
       "          0.3359, -0.3278, -0.0929, -0.5624, -0.4958, -0.4486,  0.0507,  0.8394,\n",
       "          1.5801,  0.5118, -0.1296,  0.9709,  0.4635, -0.6258,  0.7603, -0.6295,\n",
       "         -0.0763, -0.8423,  1.6255],\n",
       "        [-0.1843,  0.2023, -1.2605, -1.4261,  0.0299, -0.0031,  0.1388,  0.7102,\n",
       "         -0.6734, -0.9918,  0.4269, -0.1277, -0.6256,  0.2464, -0.5267,  2.3556,\n",
       "         -1.1540,  0.1705, -0.0199,  0.2666, -0.9382, -1.0278, -0.9612,  0.9282,\n",
       "         -0.4368, -1.4513, -0.6967],\n",
       "        [-0.1843,  0.2023, -1.2605, -1.4261,  0.0299, -0.0031,  0.1388,  0.7102,\n",
       "         -0.6734, -0.9918,  0.4269, -0.1277, -0.6256,  0.2464, -0.5267,  2.3556,\n",
       "         -1.1540,  0.1705, -0.0199,  0.2666, -0.9382, -1.0278, -0.9612,  0.9282,\n",
       "         -0.4368, -1.4513, -0.6967],\n",
       "        [-0.0254, -0.1557,  1.2283, -0.5568,  0.5874,  1.2198,  0.6772,  0.3699,\n",
       "         -1.1690,  0.6839, -0.0243, -0.1890,  1.1720, -1.0125,  0.4126, -1.1313,\n",
       "          0.1093,  0.5783, -2.1517,  1.7332,  0.1228, -0.7266, -0.3877, -0.1997,\n",
       "         -1.3826,  0.5982, -0.1662]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_enc (5, 27) @ weights (27, 27) -> (5, 27)\n",
    "# same but with 27 neurons\n",
    "\n",
    "W = torch.randn((27, 27))\n",
    "x_enc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_enc @ W).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2464)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_enc @ W)[3, 13] # 3rd x, 13th neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W has weights in columns, each col is a neuron\n",
    "# input has same number of columns as number of rows in W -> each row in x_enc is dotted with each row in W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1843,  0.2023, -1.2605, -1.4261,  0.0299, -0.0031,  0.1388,  0.7102,\n",
       "        -0.6734, -0.9918,  0.4269, -0.1277, -0.6256,  0.2464, -0.5267,  2.3556,\n",
       "        -1.1540,  0.1705, -0.0199,  0.2666, -0.9382, -1.0278, -0.9612,  0.9282,\n",
       "        -0.4368, -1.4513, -0.6967])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2464)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_enc[3] * W[:, 13]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2768,  0.3680,  6.7040,  0.6683,  0.4760,  4.1587,  0.5575,  0.6595,\n",
       "          4.6104,  0.8055,  0.8825,  0.2214,  5.2943,  0.1842,  6.1506,  4.5353,\n",
       "          1.4053,  2.0865,  0.7947,  0.9135,  0.2057,  0.4236,  8.0329, 21.9681,\n",
       "          1.3934,  0.6281,  0.7650],\n",
       "        [ 2.2961,  0.3774,  3.0401,  0.5614,  1.6870,  1.6774,  1.3435,  0.6843,\n",
       "          1.3991,  0.7205,  0.9113,  0.5699,  0.6091,  0.6385,  1.0520,  2.3150,\n",
       "          4.8555,  1.6683,  0.8784,  2.6404,  1.5897,  0.5348,  2.1388,  0.5328,\n",
       "          0.9266,  0.4307,  5.0812],\n",
       "        [ 0.8317,  1.2242,  0.2835,  0.2402,  1.0303,  0.9969,  1.1489,  2.0344,\n",
       "          0.5100,  0.3709,  1.5325,  0.8801,  0.5349,  1.2794,  0.5906, 10.5446,\n",
       "          0.3154,  1.1859,  0.9803,  1.3055,  0.3913,  0.3578,  0.3824,  2.5301,\n",
       "          0.6461,  0.2343,  0.4982],\n",
       "        [ 0.8317,  1.2242,  0.2835,  0.2402,  1.0303,  0.9969,  1.1489,  2.0344,\n",
       "          0.5100,  0.3709,  1.5325,  0.8801,  0.5349,  1.2794,  0.5906, 10.5446,\n",
       "          0.3154,  1.1859,  0.9803,  1.3055,  0.3913,  0.3578,  0.3824,  2.5301,\n",
       "          0.6461,  0.2343,  0.4982],\n",
       "        [ 0.9749,  0.8558,  3.4153,  0.5730,  1.7992,  3.3865,  1.9684,  1.4476,\n",
       "          0.3107,  1.9815,  0.9760,  0.8278,  3.2286,  0.3633,  1.5107,  0.3226,\n",
       "          1.1155,  1.7830,  0.1163,  5.6586,  1.1307,  0.4836,  0.6786,  0.8190,\n",
       "          0.2509,  1.8188,  0.8468]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need something interpretable from the model\n",
    "# going back to the matrix of counts and then probs we had in the other bigram model\n",
    "# we make 27 neurons each getting 27 inputs from the one hot encoded character\n",
    "\n",
    "(x_enc @ W).exp() # exponentiate to make values negative between 0 and 1 and positive more positive<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_enc @ W).exp().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0295, 0.0048, 0.0869, 0.0087, 0.0062, 0.0539, 0.0072, 0.0085, 0.0597,\n",
       "         0.0104, 0.0114, 0.0029, 0.0686, 0.0024, 0.0797, 0.0588, 0.0182, 0.0270,\n",
       "         0.0103, 0.0118, 0.0027, 0.0055, 0.1041, 0.2847, 0.0181, 0.0081, 0.0099],\n",
       "        [0.0558, 0.0092, 0.0739, 0.0136, 0.0410, 0.0408, 0.0326, 0.0166, 0.0340,\n",
       "         0.0175, 0.0221, 0.0138, 0.0148, 0.0155, 0.0256, 0.0562, 0.1180, 0.0405,\n",
       "         0.0213, 0.0642, 0.0386, 0.0130, 0.0520, 0.0129, 0.0225, 0.0105, 0.1235],\n",
       "        [0.0253, 0.0373, 0.0086, 0.0073, 0.0314, 0.0303, 0.0350, 0.0619, 0.0155,\n",
       "         0.0113, 0.0466, 0.0268, 0.0163, 0.0389, 0.0180, 0.3209, 0.0096, 0.0361,\n",
       "         0.0298, 0.0397, 0.0119, 0.0109, 0.0116, 0.0770, 0.0197, 0.0071, 0.0152],\n",
       "        [0.0253, 0.0373, 0.0086, 0.0073, 0.0314, 0.0303, 0.0350, 0.0619, 0.0155,\n",
       "         0.0113, 0.0466, 0.0268, 0.0163, 0.0389, 0.0180, 0.3209, 0.0096, 0.0361,\n",
       "         0.0298, 0.0397, 0.0119, 0.0109, 0.0116, 0.0770, 0.0197, 0.0071, 0.0152],\n",
       "        [0.0252, 0.0221, 0.0884, 0.0148, 0.0466, 0.0876, 0.0509, 0.0375, 0.0080,\n",
       "         0.0513, 0.0253, 0.0214, 0.0835, 0.0094, 0.0391, 0.0083, 0.0289, 0.0461,\n",
       "         0.0030, 0.1464, 0.0293, 0.0125, 0.0176, 0.0212, 0.0065, 0.0471, 0.0219]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = x_enc @ W # log counts\n",
    "counts = logits.exp() # equivalent to counts matrix we had in other bigram model\n",
    "probs = counts / counts.sum(1, keepdims=True) # normalize again across columns to get probs\n",
    "# => this is a softmax activation function\n",
    "# > allows to take in positive and negative numbers from a previous layer and makes them into a probability distribution\n",
    "#   with numbers between 0 and 1 and that sums to 1\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape # we get a matrix with 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - -\n",
      "bigram: ., e at 0, y\n",
      "input: 0\n",
      "output: tensor([0.0295, 0.0048, 0.0869, 0.0087, 0.0062, 0.0539, 0.0072, 0.0085, 0.0597,\n",
      "        0.0104, 0.0114, 0.0029, 0.0686, 0.0024, 0.0797, 0.0588, 0.0182, 0.0270,\n",
      "        0.0103, 0.0118, 0.0027, 0.0055, 0.1041, 0.2847, 0.0181, 0.0081, 0.0099])\n",
      "actual: 5\n",
      "prob by nn: 0.05389027297496796\n",
      "log likelihood : -2.9208052158355713\n",
      "negative log likelihood: 2.9208052158355713\n",
      "- - - - - -\n",
      "bigram: e, m at 5, y\n",
      "input: 5\n",
      "output: tensor([0.0558, 0.0092, 0.0739, 0.0136, 0.0410, 0.0408, 0.0326, 0.0166, 0.0340,\n",
      "        0.0175, 0.0221, 0.0138, 0.0148, 0.0155, 0.0256, 0.0562, 0.1180, 0.0405,\n",
      "        0.0213, 0.0642, 0.0386, 0.0130, 0.0520, 0.0129, 0.0225, 0.0105, 0.1235])\n",
      "actual: 13\n",
      "prob by nn: 0.01551350299268961\n",
      "log likelihood : -4.166044235229492\n",
      "negative log likelihood: 4.166044235229492\n",
      "- - - - - -\n",
      "bigram: m, m at 13, y\n",
      "input: 13\n",
      "output: tensor([0.0253, 0.0373, 0.0086, 0.0073, 0.0314, 0.0303, 0.0350, 0.0619, 0.0155,\n",
      "        0.0113, 0.0466, 0.0268, 0.0163, 0.0389, 0.0180, 0.3209, 0.0096, 0.0361,\n",
      "        0.0298, 0.0397, 0.0119, 0.0109, 0.0116, 0.0770, 0.0197, 0.0071, 0.0152])\n",
      "actual: 13\n",
      "prob by nn: 0.038934994488954544\n",
      "log likelihood : -3.245861768722534\n",
      "negative log likelihood: 3.245861768722534\n",
      "- - - - - -\n",
      "bigram: m, a at 13, y\n",
      "input: 13\n",
      "output: tensor([0.0253, 0.0373, 0.0086, 0.0073, 0.0314, 0.0303, 0.0350, 0.0619, 0.0155,\n",
      "        0.0113, 0.0466, 0.0268, 0.0163, 0.0389, 0.0180, 0.3209, 0.0096, 0.0361,\n",
      "        0.0298, 0.0397, 0.0119, 0.0109, 0.0116, 0.0770, 0.0197, 0.0071, 0.0152])\n",
      "actual: 1\n",
      "prob by nn: 0.03725524991750717\n",
      "log likelihood : -3.2899622917175293\n",
      "negative log likelihood: 3.2899622917175293\n",
      "- - - - - -\n",
      "bigram: a, . at 1, y\n",
      "input: 1\n",
      "output: tensor([0.0252, 0.0221, 0.0884, 0.0148, 0.0466, 0.0876, 0.0509, 0.0375, 0.0080,\n",
      "        0.0513, 0.0253, 0.0214, 0.0835, 0.0094, 0.0391, 0.0083, 0.0289, 0.0461,\n",
      "        0.0030, 0.1464, 0.0293, 0.0125, 0.0176, 0.0212, 0.0065, 0.0471, 0.0219])\n",
      "actual: 0\n",
      "prob by nn: 0.02522744983434677\n",
      "log likelihood : -3.6798226833343506\n",
      "negative log likelihood: 3.6798226833343506\n",
      "======\n",
      "average nll/loss =  3.4604992866516113\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    x = xs[i].item()\n",
    "    y = ys[i].item()\n",
    "    print(\"- - - - - -\")\n",
    "    print(f\"bigram: {idx2char[x]}, {idx2char[y]} at {x}, y\")\n",
    "    print(f\"input: {x}\")\n",
    "    print(f\"output: {probs[i]}\")\n",
    "    print(f\"actual: {y}\")\n",
    "    prob = probs[i, y]\n",
    "    print(f\"prob by nn: {prob}\")\n",
    "    logp = torch.log(prob)\n",
    "    print(f\"log likelihood : {logp}\")\n",
    "    nll = -logp\n",
    "    print(f\"negative log likelihood: {nll}\")\n",
    "    nlls[i] = nll\n",
    "\n",
    "print(\"======\")\n",
    "print(\"average nll/loss = \", nlls.mean().item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 13, 13,  1]), tensor([ 5, 13, 13,  1,  0]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27, 27), requires_grad=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float() # input to nn, one hot encoding\n",
    "logits = x_enc @ W # predict log counts\n",
    "counts = logits.exp() # counts equivalent to N in other bigram model\n",
    "probs = counts / counts.sum(1, keepdim=True) # probabilities for next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0268, 0.0802, 0.1136, 0.0294, 0.0155], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(5), ys] # probabilities for the next characters for each input character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.202836513519287"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs[torch.arange(5), ys].log().mean()\n",
    "loss.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad = None # set the gradients to 0\n",
    "loss.backward() # calculate the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228146"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set\n",
    "xs, ys = [], []\n",
    "\n",
    "for name in names: # use all names this time\n",
    "    chrs = [\".\"] + list(name) + [\".\"]\n",
    "    for ch1, ch2 in zip(chrs, chrs[1:]):\n",
    "        idx1 = char2idx[ch1]\n",
    "        idx2 = char2idx[ch2]\n",
    "        xs.append(idx1)\n",
    "        ys.append(idx2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 3.8021247386932373\n",
      "1: 3.4208505153656006\n",
      "2: 3.202785015106201\n",
      "3: 3.054253339767456\n",
      "4: 2.9474921226501465\n",
      "5: 2.867751359939575\n",
      "6: 2.8077304363250732\n",
      "7: 2.7623510360717773\n",
      "8: 2.727447748184204\n",
      "9: 2.6998727321624756\n",
      "10: 2.6774744987487793\n",
      "11: 2.65885329246521\n",
      "12: 2.643097162246704\n",
      "13: 2.62959361076355\n",
      "14: 2.6179041862487793\n",
      "15: 2.60770320892334\n",
      "16: 2.5987367630004883\n",
      "17: 2.5908045768737793\n",
      "18: 2.583744764328003\n",
      "19: 2.5774283409118652\n",
      "20: 2.5717477798461914\n",
      "21: 2.566615104675293\n",
      "22: 2.5619583129882812\n",
      "23: 2.5577166080474854\n",
      "24: 2.5538387298583984\n",
      "25: 2.550281047821045\n",
      "26: 2.5470077991485596\n",
      "27: 2.5439865589141846\n",
      "28: 2.5411901473999023\n",
      "29: 2.5385959148406982\n",
      "30: 2.5361826419830322\n",
      "31: 2.533933162689209\n",
      "32: 2.5318315029144287\n",
      "33: 2.52986478805542\n",
      "34: 2.528020143508911\n",
      "35: 2.5262868404388428\n",
      "36: 2.524656295776367\n",
      "37: 2.5231192111968994\n",
      "38: 2.5216686725616455\n",
      "39: 2.5202977657318115\n",
      "40: 2.519000291824341\n",
      "41: 2.517770528793335\n",
      "42: 2.516603708267212\n",
      "43: 2.515495777130127\n",
      "44: 2.514441967010498\n",
      "45: 2.513439178466797\n",
      "46: 2.512483835220337\n",
      "47: 2.5115721225738525\n",
      "48: 2.510701894760132\n",
      "49: 2.5098705291748047\n",
      "50: 2.5090749263763428\n",
      "51: 2.5083136558532715\n",
      "52: 2.507584571838379\n",
      "53: 2.506884813308716\n",
      "54: 2.506213665008545\n",
      "55: 2.5055692195892334\n",
      "56: 2.5049495697021484\n",
      "57: 2.5043535232543945\n",
      "58: 2.5037803649902344\n",
      "59: 2.503227710723877\n",
      "60: 2.502695322036743\n",
      "61: 2.5021817684173584\n",
      "62: 2.5016863346099854\n",
      "63: 2.5012073516845703\n",
      "64: 2.5007455348968506\n",
      "65: 2.500298023223877\n",
      "66: 2.4998655319213867\n",
      "67: 2.4994473457336426\n",
      "68: 2.49904203414917\n",
      "69: 2.4986495971679688\n",
      "70: 2.4982690811157227\n",
      "71: 2.4979002475738525\n",
      "72: 2.497542381286621\n",
      "73: 2.49719500541687\n",
      "74: 2.4968578815460205\n",
      "75: 2.496530532836914\n",
      "76: 2.4962124824523926\n",
      "77: 2.495903491973877\n",
      "78: 2.495603084564209\n",
      "79: 2.4953110218048096\n",
      "80: 2.4950263500213623\n",
      "81: 2.4947500228881836\n",
      "82: 2.494480848312378\n",
      "83: 2.4942188262939453\n",
      "84: 2.4939637184143066\n",
      "85: 2.4937150478363037\n",
      "86: 2.4934730529785156\n",
      "87: 2.493237018585205\n",
      "88: 2.493006944656372\n",
      "89: 2.4927830696105957\n",
      "90: 2.4925649166107178\n",
      "91: 2.492351531982422\n",
      "92: 2.492143392562866\n",
      "93: 2.491940498352051\n",
      "94: 2.4917426109313965\n",
      "95: 2.491549491882324\n",
      "96: 2.491360902786255\n",
      "97: 2.4911768436431885\n",
      "98: 2.490997076034546\n",
      "99: 2.490821361541748\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn((27, 27), requires_grad=True)\n",
    "\n",
    "losses = []\n",
    "for k in range(100):\n",
    "\n",
    "    # forward\n",
    "    x_enc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = x_enc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean() # loss + regularization (see model smoothing in other bigrams)\n",
    "\n",
    "    # backward\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -50 * W.grad\n",
    "\n",
    "    print(f\"{k}: {loss.item()}\")\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18e1a818700>]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this gets quite close to the manual approach before, this time with gradient based learning\n",
    "- makes sense that it's not better because there is no additional information\n",
    "- easier here to keep them in a table, gradient based is much more flexible in how it can be expanded\n",
    "\n",
    "- only thing that will fundamentally change is how we get logits. we can in more information here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e.\n",
      "yayashusha.\n",
      "sia.\n",
      "ma.\n",
      "kaha.\n",
      "rer.\n",
      "kj.\n",
      "klinditigfl.\n",
      "aryza.\n",
      "tene.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        x_enc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = x_enc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "        out.append(idx2char[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(\"\".join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
