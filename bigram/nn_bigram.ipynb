{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"working_directory_corrected\" in vars():\n",
    "    %cd ..\n",
    "    working_directory_corrected = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Bigrams\n",
    "- same approach as with the pure bigram model based on the probabilities of the data set, this time with a neural net with gradient based optimization\n",
    "- idea is to predict a probability distribution based on the last character to find the new character\n",
    "- the model is trained on list of names with the average negative log likelihood loss function established in the previous bigram model\n",
    "- the label for each data point will be the next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = open(\"data/names.txt\").read().splitlines()\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [\".\"] + sorted(list(set(\"\".join(names))))\n",
    "char2idx = {c: i for i, c in enumerate(chars)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n"
     ]
    }
   ],
   "source": [
    "# training set\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "for name in names[:1]:\n",
    "    chrs = [\".\"] + list(name) + [\".\"]\n",
    "    for ch1, ch2 in zip(chrs, chrs[1:]):\n",
    "        idx1 = char2idx[ch1]\n",
    "        idx2 = char2idx[ch2]\n",
    "        print(ch1, ch2)\n",
    "        xs.append(idx1)\n",
    "        ys.append(idx2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 13, 13,  1]), tensor([ 5, 13, 13,  1,  0]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc = F.one_hot(xs, num_classes=27).float() # casting to float so nn can work with it\n",
    "x_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x154a069dc30>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAACHCAYAAABK4hAcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAN2klEQVR4nO3df2hV9ePH8dfd2q4/urs6137cNufUUmpukrolkgkbTgvJ9A8r/1hDjOoqzlHJAl1CsDAIqSQjKP/xV0ImyQdDlpsE8wcTMaH21SFfr8xtKR/vdOZcu+/PH3263+9Nnd7tvXt2r88HHLj33Df3vHjzlr0899x7XMYYIwAAAAuSnA4AAAASB8UCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANY8EsuDhUIhtbe3y+PxyOVyxfLQAABgkIwxun79unw+n5KSBj4nEdNi0d7erry8vFgeEgAAWBIIBJSbmzvgmJgWC4/HI0n631OTlPbo0D6FefnJGTYiAQCA+/hTffpZ/wr/HR9ITIvF3x9/pD2apDTP0IrFI64UG5EAAMD9/PfmHw9yGQMXbwIAAGsoFgAAwBqKBQAAsGZQxWLbtm2aNGmSRo0apdLSUp04ccJ2LgAAEIeiLhZ79+5VTU2N6urqdOrUKRUXF6uiokJdXV3DkQ8AAMSRqIvFJ598otWrV6uqqkpPPfWUtm/frjFjxujrr78ejnwAACCORFUsbt++rZaWFpWXl//fGyQlqby8XM3NzXeM7+3tVXd3d8QGAAASV1TF4sqVK+rv71dWVlbE/qysLHV0dNwxvr6+Xl6vN7zxq5sAACS2Yf1WSG1trYLBYHgLBALDeTgAAOCwqH55MyMjQ8nJyers7IzY39nZqezs7DvGu91uud3uoSUEAABxI6ozFqmpqZo1a5YaGhrC+0KhkBoaGjR37lzr4QAAQHyJ+l4hNTU1qqys1OzZs1VSUqKtW7eqp6dHVVVVw5EPAADEkaiLxYoVK/T7779r06ZN6ujo0MyZM3Xo0KE7LugEAAAPH5cxxsTqYN3d3fJ6vfr3/0we8t1NK3wz7YQCAAAD+tP0qVEHFAwGlZaWNuBY7hUCAACsifqjEBtefnKGHnGlOHHoh86P7aetvA9niAAAD4IzFgAAwBqKBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALCGYgEAAKyhWAAAAGsoFgAAwBqKBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACw5hGnA2B4VfhmOh0BCeLH9tNW3oc1CSQ2zlgAAABrKBYAAMAaigUAALCGYgEAAKyJqljU19drzpw58ng8yszM1NKlS9Xa2jpc2QAAQJyJqlg0NTXJ7/fr2LFjOnz4sPr6+rRw4UL19PQMVz4AABBHovq66aFDhyKe79ixQ5mZmWppadH8+fOtBgMAAPFnSL9jEQwGJUnp6el3fb23t1e9vb3h593d3UM5HAAAGOEGffFmKBRSdXW15s2bp8LCwruOqa+vl9frDW95eXmDDgoAAEa+QRcLv9+vs2fPas+ePfccU1tbq2AwGN4CgcBgDwcAAOLAoD4KWbNmjQ4ePKijR48qNzf3nuPcbrfcbvegwwEAgPgSVbEwxmjt2rXav3+/GhsbVVBQMFy5AABAHIqqWPj9fu3atUsHDhyQx+NRR0eHJMnr9Wr06NHDEhAAAMSPqK6x+OKLLxQMBrVgwQLl5OSEt7179w5XPgAAEEei/igEAADgXrhXCAAAsIZiAQAArKFYAAAAaygWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALCGYgEAAKyhWAAAAGsoFgAAwBqKBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALDmEacDDNaP7aetvVeFb6a19wISFf9OADwIzlgAAABrKBYAAMAaigUAALCGYgEAAKwZUrH46KOP5HK5VF1dbSkOAACIZ4MuFidPntSXX36poqIim3kAAEAcG1SxuHHjhlauXKmvvvpK48ePt50JAADEqUEVC7/frxdffFHl5eUDjuvt7VV3d3fEBgAAElfUP5C1Z88enTp1SidPnrzv2Pr6em3evHlQwQAAQPyJ6oxFIBDQunXrtHPnTo0aNeq+42traxUMBsNbIBAYdFAAADDyRXXGoqWlRV1dXXrmmWfC+/r7+3X06FF9/vnn6u3tVXJycvg1t9stt9ttLy0AABjRoioWZWVl+uWXXyL2VVVVafr06dqwYUNEqQAAAA+fqIqFx+NRYWFhxL6xY8dqwoQJd+wHAAAPH355EwAAWDPk26Y3NjZaiAEAABIBZywAAIA1Qz5jEQ1jjCTpT/VJZmjv1X09ZCHRX/40fdbeCwCARPOn/vo7+fff8YG4zIOMsuTSpUvKy8uL1eEAAIBFgUBAubm5A46JabEIhUJqb2+Xx+ORy+W657ju7m7l5eUpEAgoLS0tVvEeWsx37DDXscV8xxbzHVuxnG9jjK5fvy6fz6ekpIGvoojpRyFJSUn3bTr/X1paGoszhpjv2GGuY4v5ji3mO7ZiNd9er/eBxnHxJgAAsIZiAQAArBmRxcLtdquuro77jMQI8x07zHVsMd+xxXzH1kid75hevAkAABLbiDxjAQAA4hPFAgAAWEOxAAAA1lAsAACANRQLAABgzYgrFtu2bdOkSZM0atQolZaW6sSJE05HSkgffPCBXC5XxDZ9+nSnYyWMo0ePasmSJfL5fHK5XPr+++8jXjfGaNOmTcrJydHo0aNVXl6uc+fOORM2Adxvvl9//fU71vuiRYucCRvn6uvrNWfOHHk8HmVmZmrp0qVqbW2NGHPr1i35/X5NmDBBjz76qJYvX67Ozk6HEse3B5nvBQsW3LG+33zzTYcSj7BisXfvXtXU1Kiurk6nTp1ScXGxKioq1NXV5XS0hPT000/r8uXL4e3nn392OlLC6OnpUXFxsbZt23bX17ds2aJPP/1U27dv1/HjxzV27FhVVFTo1q1bMU6aGO4335K0aNGiiPW+e/fuGCZMHE1NTfL7/Tp27JgOHz6svr4+LVy4UD09PeEx69ev1w8//KB9+/apqalJ7e3tWrZsmYOp49eDzLckrV69OmJ9b9myxaHEkswIUlJSYvx+f/h5f3+/8fl8pr6+3sFUiamurs4UFxc7HeOhIMns378//DwUCpns7Gzz8ccfh/ddu3bNuN1us3v3bgcSJpZ/zrcxxlRWVpqXXnrJkTyJrqury0gyTU1Nxpi/1nJKSorZt29feMyvv/5qJJnm5manYiaMf863McY8//zzZt26dc6F+ocRc8bi9u3bamlpUXl5eXhfUlKSysvL1dzc7GCyxHXu3Dn5fD5NnjxZK1eu1MWLF52O9FC4cOGCOjo6Ita61+tVaWkpa30YNTY2KjMzU9OmTdNbb72lq1evOh0pIQSDQUlSenq6JKmlpUV9fX0R63v69OmaOHEi69uCf87333bu3KmMjAwVFhaqtrZWN2/edCKepBjf3XQgV65cUX9/v7KysiL2Z2Vl6bfffnMoVeIqLS3Vjh07NG3aNF2+fFmbN2/Wc889p7Nnz8rj8TgdL6F1dHRI0l3X+t+vwa5FixZp2bJlKigoUFtbm95//30tXrxYzc3NSk5Odjpe3AqFQqqurta8efNUWFgo6a/1nZqaqnHjxkWMZX0P3d3mW5Jee+015efny+fz6cyZM9qwYYNaW1v13XffOZJzxBQLxNbixYvDj4uKilRaWqr8/Hx9++23WrVqlYPJAPteeeWV8OMZM2aoqKhIU6ZMUWNjo8rKyhxMFt/8fr/Onj3L9Vkxcq/5fuONN8KPZ8yYoZycHJWVlamtrU1TpkyJdcyRc/FmRkaGkpOT77hyuLOzU9nZ2Q6leniMGzdOTz75pM6fP+90lIT393pmrTtn8uTJysjIYL0PwZo1a3Tw4EEdOXJEubm54f3Z2dm6ffu2rl27FjGe9T0095rvuyktLZUkx9b3iCkWqampmjVrlhoaGsL7QqGQGhoaNHfuXAeTPRxu3LihtrY25eTkOB0l4RUUFCg7OztirXd3d+v48eOs9Ri5dOmSrl69ynofBGOM1qxZo/379+unn35SQUFBxOuzZs1SSkpKxPpubW3VxYsXWd+DcL/5vpvTp09LkmPre0R9FFJTU6PKykrNnj1bJSUl2rp1q3p6elRVVeV0tITzzjvvaMmSJcrPz1d7e7vq6uqUnJysV1991eloCeHGjRsR/1u4cOGCTp8+rfT0dE2cOFHV1dX68MMP9cQTT6igoEAbN26Uz+fT0qVLnQsdxwaa7/T0dG3evFnLly9Xdna22tra9N5772nq1KmqqKhwMHV88vv92rVrlw4cOCCPxxO+bsLr9Wr06NHyer1atWqVampqlJ6errS0NK1du1Zz587Vs88+63D6+HO/+W5ra9OuXbv0wgsvaMKECTpz5ozWr1+v+fPnq6ioyJnQTn8t5Z8+++wzM3HiRJOammpKSkrMsWPHnI6UkFasWGFycnJMamqqefzxx82KFSvM+fPnnY6VMI4cOWIk3bFVVlYaY/76yunGjRtNVlaWcbvdpqyszLS2tjobOo4NNN83b940CxcuNI899phJSUkx+fn5ZvXq1aajo8Pp2HHpbvMsyXzzzTfhMX/88Yd5++23zfjx482YMWPMyy+/bC5fvuxc6Dh2v/m+ePGimT9/vklPTzdut9tMnTrVvPvuuyYYDDqW2fXf4AAAAEM2Yq6xAAAA8Y9iAQAArKFYAAAAaygWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALCGYgEAAKyhWAAAAGv+A6sEjbDe9GoiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[-4.4146e-01],\n",
       "         [ 1.5231e-01],\n",
       "         [-1.4494e+00],\n",
       "         [ 2.7560e-01],\n",
       "         [ 5.6116e-01],\n",
       "         [-1.1113e+00],\n",
       "         [ 7.7931e-01],\n",
       "         [ 2.4191e+00],\n",
       "         [-1.0940e+00],\n",
       "         [ 1.5545e-01],\n",
       "         [-2.3725e+00],\n",
       "         [-1.3023e-03],\n",
       "         [-1.1881e+00],\n",
       "         [ 8.5135e-02],\n",
       "         [-1.9048e+00],\n",
       "         [ 2.9070e-01],\n",
       "         [-3.5313e-01],\n",
       "         [-1.0722e+00],\n",
       "         [-5.1447e-01],\n",
       "         [-7.4201e-02],\n",
       "         [ 2.2884e+00],\n",
       "         [-2.9785e-01],\n",
       "         [-1.9074e+00],\n",
       "         [-1.4741e+00],\n",
       "         [-1.1165e+00],\n",
       "         [-1.0543e+00],\n",
       "         [-1.2944e+00]]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc, torch.randn((27, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0084],\n",
       "        [-0.5313],\n",
       "        [-2.1653],\n",
       "        [-2.1653],\n",
       "        [-0.5696]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing weights\n",
    "# doing matrix multiplication with the encoded x's (batch of multiple)\n",
    "# this will feed in all x's into every neuron at the same time, pytorch can do this in parallel\n",
    "\n",
    "# x_enc (5, 27) @ weights (27, 1) -> (5, 1)\n",
    "\n",
    "W = torch.randn((27, 1)) # -> one neuron, 27 inputs, one for each possible character\n",
    "x_enc @ W # returns (5, 1) for 5 input x's, one activation which is dot product between the encoded x and the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5996,  1.0208, -0.3593, -0.2678, -1.4562,  0.7491,  1.3048, -0.3991,\n",
       "          1.4082, -0.8975, -0.5598,  0.3048, -2.1028, -1.1919,  1.6081, -0.8740,\n",
       "          0.5782, -1.4467,  0.3671, -2.0086, -0.8246,  1.2905, -1.0359,  0.9531,\n",
       "         -1.2308,  0.3878,  1.9702],\n",
       "        [-0.2209,  0.4474,  0.3278,  2.4503, -0.6734, -1.6493,  0.5323, -0.9814,\n",
       "         -0.2742, -1.3150,  0.6342, -0.2930, -0.8035,  0.4831, -0.1035,  1.1340,\n",
       "         -1.1494, -0.7491, -0.6364, -1.9128, -0.2590,  0.9590, -0.2037, -0.6917,\n",
       "          1.0863, -2.2623,  0.1662],\n",
       "        [ 0.2401, -0.4756, -0.2860, -0.0945,  1.0118, -1.1178, -1.3437,  0.3383,\n",
       "         -1.4291, -0.9784, -1.0982,  0.2308, -2.2329, -1.6857,  0.9106,  0.1198,\n",
       "          0.2822,  0.1316, -0.5156, -0.4164, -0.4640, -0.1477,  2.0853,  0.4599,\n",
       "          0.8305, -0.0140,  0.4603],\n",
       "        [ 0.2401, -0.4756, -0.2860, -0.0945,  1.0118, -1.1178, -1.3437,  0.3383,\n",
       "         -1.4291, -0.9784, -1.0982,  0.2308, -2.2329, -1.6857,  0.9106,  0.1198,\n",
       "          0.2822,  0.1316, -0.5156, -0.4164, -0.4640, -0.1477,  2.0853,  0.4599,\n",
       "          0.8305, -0.0140,  0.4603],\n",
       "        [-0.8805,  0.0467, -0.7287,  0.0315,  0.2370, -0.7716, -2.2913,  0.8501,\n",
       "          0.8176,  0.3070, -0.2449,  0.2545, -1.0376, -0.5935, -0.6045, -2.3983,\n",
       "         -0.4927,  2.2502, -0.0251,  1.1727, -0.7952,  0.6557,  0.6983, -0.2961,\n",
       "          0.2955,  0.1841,  0.4969]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_enc (5, 27) @ weights (27, 27) -> (5, 27)\n",
    "# same but with 27 neurons\n",
    "\n",
    "W = torch.randn((27, 27))\n",
    "x_enc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_enc @ W).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.6857)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_enc @ W)[3, 13] # 3rd x, 13th neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W has weights in columns, each col is a neuron\n",
    "# input has same number of columns as number of rows in W -> each row in x_enc is dotted with each row in W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2401, -0.4756, -0.2860, -0.0945,  1.0118, -1.1178, -1.3437,  0.3383,\n",
       "        -1.4291, -0.9784, -1.0982,  0.2308, -2.2329, -1.6857,  0.9106,  0.1198,\n",
       "         0.2822,  0.1316, -0.5156, -0.4164, -0.4640, -0.1477,  2.0853,  0.4599,\n",
       "         0.8305, -0.0140,  0.4603])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.6857)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_enc[3] * W[:, 13]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5491,  2.7755,  0.6982,  0.7650,  0.2331,  2.1152,  3.6869,  0.6709,\n",
       "          4.0884,  0.4076,  0.5713,  1.3564,  0.1221,  0.3037,  4.9931,  0.4173,\n",
       "          1.7828,  0.2354,  1.4435,  0.1342,  0.4384,  3.6346,  0.3549,  2.5937,\n",
       "          0.2920,  1.4738,  7.1724],\n",
       "        [ 0.8018,  1.5642,  1.3879, 11.5914,  0.5100,  0.1922,  1.7028,  0.3748,\n",
       "          0.7602,  0.2685,  1.8855,  0.7460,  0.4478,  1.6210,  0.9017,  3.1081,\n",
       "          0.3168,  0.4728,  0.5292,  0.1477,  0.7718,  2.6090,  0.8157,  0.5007,\n",
       "          2.9632,  0.1041,  1.1808],\n",
       "        [ 1.2713,  0.6215,  0.7513,  0.9098,  2.7506,  0.3270,  0.2609,  1.4025,\n",
       "          0.2395,  0.3759,  0.3335,  1.2596,  0.1072,  0.1853,  2.4858,  1.1272,\n",
       "          1.3260,  1.1407,  0.5971,  0.6594,  0.6287,  0.8627,  8.0466,  1.5839,\n",
       "          2.2944,  0.9861,  1.5845],\n",
       "        [ 1.2713,  0.6215,  0.7513,  0.9098,  2.7506,  0.3270,  0.2609,  1.4025,\n",
       "          0.2395,  0.3759,  0.3335,  1.2596,  0.1072,  0.1853,  2.4858,  1.1272,\n",
       "          1.3260,  1.1407,  0.5971,  0.6594,  0.6287,  0.8627,  8.0466,  1.5839,\n",
       "          2.2944,  0.9861,  1.5845],\n",
       "        [ 0.4146,  1.0478,  0.4825,  1.0320,  1.2675,  0.4623,  0.1011,  2.3399,\n",
       "          2.2650,  1.3593,  0.7828,  1.2899,  0.3543,  0.5524,  0.5464,  0.0909,\n",
       "          0.6110,  9.4898,  0.9752,  3.2307,  0.4515,  1.9265,  2.0102,  0.7437,\n",
       "          1.3438,  1.2021,  1.6437]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need something interpretable from the model\n",
    "# going back to the matrix of counts and then probs we had in the other bigram model\n",
    "# we make 27 neurons each getting 27 inputs from the one hot encoded character\n",
    "\n",
    "(x_enc @ W).exp() # exponentiate to make values negative between 0 and 1 and positive more positive<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_enc @ W).exp().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0127, 0.0641, 0.0161, 0.0177, 0.0054, 0.0488, 0.0851, 0.0155, 0.0944,\n",
       "         0.0094, 0.0132, 0.0313, 0.0028, 0.0070, 0.1153, 0.0096, 0.0412, 0.0054,\n",
       "         0.0333, 0.0031, 0.0101, 0.0839, 0.0082, 0.0599, 0.0067, 0.0340, 0.1656],\n",
       "        [0.0209, 0.0409, 0.0363, 0.3028, 0.0133, 0.0050, 0.0445, 0.0098, 0.0199,\n",
       "         0.0070, 0.0493, 0.0195, 0.0117, 0.0424, 0.0236, 0.0812, 0.0083, 0.0124,\n",
       "         0.0138, 0.0039, 0.0202, 0.0682, 0.0213, 0.0131, 0.0774, 0.0027, 0.0309],\n",
       "        [0.0373, 0.0182, 0.0220, 0.0267, 0.0806, 0.0096, 0.0076, 0.0411, 0.0070,\n",
       "         0.0110, 0.0098, 0.0369, 0.0031, 0.0054, 0.0729, 0.0330, 0.0389, 0.0334,\n",
       "         0.0175, 0.0193, 0.0184, 0.0253, 0.2358, 0.0464, 0.0672, 0.0289, 0.0464],\n",
       "        [0.0373, 0.0182, 0.0220, 0.0267, 0.0806, 0.0096, 0.0076, 0.0411, 0.0070,\n",
       "         0.0110, 0.0098, 0.0369, 0.0031, 0.0054, 0.0729, 0.0330, 0.0389, 0.0334,\n",
       "         0.0175, 0.0193, 0.0184, 0.0253, 0.2358, 0.0464, 0.0672, 0.0289, 0.0464],\n",
       "        [0.0109, 0.0276, 0.0127, 0.0271, 0.0333, 0.0122, 0.0027, 0.0615, 0.0596,\n",
       "         0.0358, 0.0206, 0.0339, 0.0093, 0.0145, 0.0144, 0.0024, 0.0161, 0.2496,\n",
       "         0.0257, 0.0850, 0.0119, 0.0507, 0.0529, 0.0196, 0.0353, 0.0316, 0.0432]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = x_enc @ W # log counts\n",
    "counts = logits.exp() # equivalent to counts matrix we had in other bigram model\n",
    "probs = counts / counts.sum(1, keepdims=True) # normalize again across columns to get probs\n",
    "# => this is a softmax activation function\n",
    "# > allows to take in positive and negative numbers from a previous layer and makes them into a probability distribution\n",
    "#   with numbers between 0 and 1 and that sums to 1\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape # we get a matrix with 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - -\n",
      "bigram: ., e at 0, y\n",
      "input: 0\n",
      "output: tensor([0.0127, 0.0641, 0.0161, 0.0177, 0.0054, 0.0488, 0.0851, 0.0155, 0.0944,\n",
      "        0.0094, 0.0132, 0.0313, 0.0028, 0.0070, 0.1153, 0.0096, 0.0412, 0.0054,\n",
      "        0.0333, 0.0031, 0.0101, 0.0839, 0.0082, 0.0599, 0.0067, 0.0340, 0.1656])\n",
      "actual: 5\n",
      "prob by nn: 0.0488387793302536\n",
      "log likelihood : -3.019230604171753\n",
      "negative log likelihood: 3.019230604171753\n",
      "- - - - - -\n",
      "bigram: e, m at 5, y\n",
      "input: 5\n",
      "output: tensor([0.0209, 0.0409, 0.0363, 0.3028, 0.0133, 0.0050, 0.0445, 0.0098, 0.0199,\n",
      "        0.0070, 0.0493, 0.0195, 0.0117, 0.0424, 0.0236, 0.0812, 0.0083, 0.0124,\n",
      "        0.0138, 0.0039, 0.0202, 0.0682, 0.0213, 0.0131, 0.0774, 0.0027, 0.0309])\n",
      "actual: 13\n",
      "prob by nn: 0.04235075041651726\n",
      "log likelihood : -3.161769151687622\n",
      "negative log likelihood: 3.161769151687622\n",
      "- - - - - -\n",
      "bigram: m, m at 13, y\n",
      "input: 13\n",
      "output: tensor([0.0373, 0.0182, 0.0220, 0.0267, 0.0806, 0.0096, 0.0076, 0.0411, 0.0070,\n",
      "        0.0110, 0.0098, 0.0369, 0.0031, 0.0054, 0.0729, 0.0330, 0.0389, 0.0334,\n",
      "        0.0175, 0.0193, 0.0184, 0.0253, 0.2358, 0.0464, 0.0672, 0.0289, 0.0464])\n",
      "actual: 13\n",
      "prob by nn: 0.005431673023849726\n",
      "log likelihood : -5.215507984161377\n",
      "negative log likelihood: 5.215507984161377\n",
      "- - - - - -\n",
      "bigram: m, a at 13, y\n",
      "input: 13\n",
      "output: tensor([0.0373, 0.0182, 0.0220, 0.0267, 0.0806, 0.0096, 0.0076, 0.0411, 0.0070,\n",
      "        0.0110, 0.0098, 0.0369, 0.0031, 0.0054, 0.0729, 0.0330, 0.0389, 0.0334,\n",
      "        0.0175, 0.0193, 0.0184, 0.0253, 0.2358, 0.0464, 0.0672, 0.0289, 0.0464])\n",
      "actual: 1\n",
      "prob by nn: 0.018216732889413834\n",
      "log likelihood : -4.0054144859313965\n",
      "negative log likelihood: 4.0054144859313965\n",
      "- - - - - -\n",
      "bigram: a, . at 1, y\n",
      "input: 1\n",
      "output: tensor([0.0109, 0.0276, 0.0127, 0.0271, 0.0333, 0.0122, 0.0027, 0.0615, 0.0596,\n",
      "        0.0358, 0.0206, 0.0339, 0.0093, 0.0145, 0.0144, 0.0024, 0.0161, 0.2496,\n",
      "        0.0257, 0.0850, 0.0119, 0.0507, 0.0529, 0.0196, 0.0353, 0.0316, 0.0432])\n",
      "actual: 0\n",
      "prob by nn: 0.010904931463301182\n",
      "log likelihood : -4.518540382385254\n",
      "negative log likelihood: 4.518540382385254\n",
      "======\n",
      "average nll/loss =  3.9840927124023438\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    x = xs[i].item()\n",
    "    y = ys[i].item()\n",
    "    print(\"- - - - - -\")\n",
    "    print(f\"bigram: {idx2char[x]}, {idx2char[y]} at {x}, y\")\n",
    "    print(f\"input: {x}\")\n",
    "    print(f\"output: {probs[i]}\")\n",
    "    print(f\"actual: {y}\")\n",
    "    prob = probs[i, y]\n",
    "    print(f\"prob by nn: {prob}\")\n",
    "    logp = torch.log(prob)\n",
    "    print(f\"log likelihood : {logp}\")\n",
    "    nll = -logp\n",
    "    print(f\"negative log likelihood: {nll}\")\n",
    "    nlls[i] = nll\n",
    "\n",
    "print(\"======\")\n",
    "print(\"average nll/loss = \", nlls.mean().item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 13, 13,  1]), tensor([ 5, 13, 13,  1,  0]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27, 27), requires_grad=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float() # input to nn, one hot encoding\n",
    "logits = x_enc @ W # predict log counts\n",
    "counts = logits.exp() # counts equivalent to N in other bigram model\n",
    "probs = counts / counts.sum(1, keepdim=True) # probabilities for next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0768, 0.0040, 0.0646, 0.0689, 0.1525], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(5), ys] # probabilities for the next characters for each input character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.077178478240967"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs[torch.arange(5), ys].log().mean()\n",
    "loss.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad = None # set the gradients to 0\n",
    "loss.backward() # calculate the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228146"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set\n",
    "xs, ys = [], []\n",
    "\n",
    "for name in names: # use all names this time\n",
    "    chrs = [\".\"] + list(name) + [\".\"]\n",
    "    for ch1, ch2 in zip(chrs, chrs[1:]):\n",
    "        idx1 = char2idx[ch1]\n",
    "        idx2 = char2idx[ch2]\n",
    "        xs.append(idx1)\n",
    "        ys.append(idx2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 3.8108768463134766\n",
      "1: 3.4195897579193115\n",
      "2: 3.1692888736724854\n",
      "3: 3.0117223262786865\n",
      "4: 2.9107789993286133\n",
      "5: 2.837972640991211\n",
      "6: 2.7843844890594482\n",
      "7: 2.744659185409546\n",
      "8: 2.7144103050231934\n",
      "9: 2.6904869079589844\n",
      "10: 2.6708831787109375\n",
      "11: 2.6543824672698975\n",
      "12: 2.640231132507324\n",
      "13: 2.627938747406006\n",
      "14: 2.6171650886535645\n",
      "15: 2.607661008834839\n",
      "16: 2.599233388900757\n",
      "17: 2.591726064682007\n",
      "18: 2.5850095748901367\n",
      "19: 2.5789730548858643\n",
      "20: 2.57352352142334\n",
      "21: 2.5685830116271973\n",
      "22: 2.5640835762023926\n",
      "23: 2.5599710941314697\n",
      "24: 2.556197166442871\n",
      "25: 2.552722692489624\n",
      "26: 2.549513101577759\n",
      "27: 2.546539068222046\n",
      "28: 2.5437750816345215\n",
      "29: 2.5411994457244873\n",
      "30: 2.5387935638427734\n",
      "31: 2.5365402698516846\n",
      "32: 2.534425735473633\n",
      "33: 2.5324363708496094\n",
      "34: 2.530561923980713\n",
      "35: 2.5287926197052\n",
      "36: 2.5271193981170654\n",
      "37: 2.5255343914031982\n",
      "38: 2.524031400680542\n",
      "39: 2.52260422706604\n",
      "40: 2.521246910095215\n",
      "41: 2.519955635070801\n",
      "42: 2.5187246799468994\n",
      "43: 2.5175511837005615\n",
      "44: 2.516430616378784\n",
      "45: 2.515359878540039\n",
      "46: 2.514336109161377\n",
      "47: 2.5133559703826904\n",
      "48: 2.512417793273926\n",
      "49: 2.511518716812134\n",
      "50: 2.5106563568115234\n",
      "51: 2.509828567504883\n",
      "52: 2.5090339183807373\n",
      "53: 2.508270502090454\n",
      "54: 2.5075366497039795\n",
      "55: 2.5068302154541016\n",
      "56: 2.506150960922241\n",
      "57: 2.5054962635040283\n",
      "58: 2.504865884780884\n",
      "59: 2.5042576789855957\n",
      "60: 2.503671646118164\n",
      "61: 2.503105878829956\n",
      "62: 2.5025596618652344\n",
      "63: 2.502032518386841\n",
      "64: 2.5015227794647217\n",
      "65: 2.5010299682617188\n",
      "66: 2.500553607940674\n",
      "67: 2.5000927448272705\n",
      "68: 2.4996464252471924\n",
      "69: 2.4992144107818604\n",
      "70: 2.498796224594116\n",
      "71: 2.4983911514282227\n",
      "72: 2.4979982376098633\n",
      "73: 2.497617483139038\n",
      "74: 2.4972481727600098\n",
      "75: 2.496889352798462\n",
      "76: 2.4965415000915527\n",
      "77: 2.496204137802124\n",
      "78: 2.4958760738372803\n",
      "79: 2.4955575466156006\n",
      "80: 2.4952478408813477\n",
      "81: 2.4949471950531006\n",
      "82: 2.494654893875122\n",
      "83: 2.494370460510254\n",
      "84: 2.494094133377075\n",
      "85: 2.4938249588012695\n",
      "86: 2.493563413619995\n",
      "87: 2.4933087825775146\n",
      "88: 2.493060827255249\n",
      "89: 2.492819309234619\n",
      "90: 2.492584228515625\n",
      "91: 2.4923551082611084\n",
      "92: 2.4921321868896484\n",
      "93: 2.4919145107269287\n",
      "94: 2.4917025566101074\n",
      "95: 2.4914956092834473\n",
      "96: 2.4912946224212646\n",
      "97: 2.491097927093506\n",
      "98: 2.4909064769744873\n",
      "99: 2.4907195568084717\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn((27, 27), requires_grad=True)\n",
    "\n",
    "losses = []\n",
    "for k in range(100):\n",
    "\n",
    "    # forward\n",
    "    x_enc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = x_enc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean() # loss + regularization (see model smoothing in other bigrams)\n",
    "\n",
    "    # backward\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -50 * W.grad\n",
    "\n",
    "    print(f\"{k}: {loss.item()}\")\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x154a071ad70>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3WUlEQVR4nO3deXRUdZ7//9etqlRlrYQAWUjComwixFZUDLh9FVvFoaUXZxppgyPdjojd6HxnRuPatj8MPU57munpxqVd+vvtzjDqiNoK8rXFSDOyCwqiIAKCkBC2pEKWSlJ1f3/UkgSSkEoqdbM8H+fUSdW9n6p6c08f69Wfz+d+PoZpmqYAAAAsYrO6AAAAMLARRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAlnJYXUBn+P1+HT58WCkpKTIMw+pyAABAJ5imqerqag0bNkw2W/v9H30ijBw+fFh5eXlWlwEAALrg4MGDys3Nbfd8nwgjKSkpkgL/GLfbbXE1AACgMzwej/Ly8sK/4+3pE2EkNDTjdrsJIwAA9DFnm2LBBFYAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALBVRGFm6dKny8/PDG9YVFBRo5cqVHb7n17/+tcaNG6eEhATl5eXpvvvuU319fbeKjpYX1+7To2/u0O4j1VaXAgDAgBXRrr25ublavHixxowZI9M09Yc//EE333yztm7dqvPPP/+M9iUlJXrggQf04osvaurUqdq9e7duv/12GYahp59+Omr/iK7686eHtfVApaaNHqKxmR1vbwwAAHpGRGFk5syZrV4vWrRIS5cu1fr169sMIx999JGmTZumW2+9VZI0cuRIzZ49Wxs2bOhGydGT5Az88+safBZXAgDAwNXlOSM+n0/Lli1TTU2NCgoK2mwzdepUbdmyRRs3bpQk7d27VytWrNCMGTM6/Gyv1yuPx9Pq0RMSnXZJUk1DU498PgAAOLuIekYkafv27SooKFB9fb2Sk5O1fPlyTZgwoc22t956q44dO6bLL79cpmmqqalJd911lx588MEOv6O4uFiPP/54pKVFLBRGar30jAAAYJWIe0bGjRunbdu2acOGDZo/f77mzp2rnTt3ttm2tLRUTz75pH73u9/p448/1uuvv6533nlHTzzxRIffUVRUpKqqqvDj4MGDkZbZKYmuQBarZZgGAADLRNwz4nQ6NXr0aEnS5MmTtWnTJi1ZskTPPvvsGW0feeQR3Xbbbfrxj38sSZo0aZJqamp055136qGHHpLN1nYWcrlccrlckZYWsaRQzwjDNAAAWKbb64z4/X55vd42z9XW1p4ROOz2QAAwTbO7X91tCcEJrMwZAQDAOhH1jBQVFenGG2/U8OHDVV1drZKSEpWWlmrVqlWSpMLCQuXk5Ki4uFhS4O6bp59+WhdeeKGmTJmiPXv26JFHHtHMmTPDocRKScwZAQDAchGFkYqKChUWFqqsrEypqanKz8/XqlWrdN1110mSDhw40Kon5OGHH5ZhGHr44Yd16NAhDR06VDNnztSiRYui+6/oIuaMAABgPcPsDeMlZ+HxeJSamqqqqiq53e6ofe7rH3+jf3zlE10xZoj+77wpUftcAADQ+d/vAb03TfjWXnpGAACwzAAPIwzTAABgtQEdRpJc3NoLAIDVBnQYSYgL3trL3TQAAFhmQIcRekYAALDegA4joTkjdY0++f29/qYiAAD6pQEdRkI9I6Yp1TcxVAMAgBUGdBiJdzSvAsu8EQAArDGgw4jNZoTXGqnj9l4AACwxoMOI1DxvhM3yAACwBmHEyR01AABYiTASDCPMGQEAwBoDPowksXMvAACWGvBhhGEaAACsRRgJDdPQMwIAgCUGfBhJCq3CSs8IAACWGPBhJNHFBFYAAKxEGHGGJrDSMwIAgBUII+EJrPSMAABghQEfRpKc3NoLAICVBnwYSQgvesYwDQAAVhjwYSTJxTANAABWGvBhhAmsAABYizDCBFYAACxFGAn2jNTQMwIAgCUGfBgJzRmpo2cEAABLEEZCPSOswAoAgCUGfBgJ3dpb1+iTz29aXA0AAAPPgA8joZ4RKRBIAABAbA34MBIfZ5NhBJ5zey8AALE34MOIYRhKjAve3su8EQAAYm7AhxFJSnRxey8AAFYhjEhKcnJ7LwAAViGMqOXCZ4QRAABijTCiFkvCs3MvAAAxRxhRyzkj9IwAABBrhBG1nDNCzwgAALFGGFHzKqz0jAAAEHuEETWvwsqcEQAAYo8wIikxuHNvLT0jAADEXERhZOnSpcrPz5fb7Zbb7VZBQYFWrlzZ4XsqKyu1YMECZWdny+VyaezYsVqxYkW3io62xDgmsAIAYBXH2Zs0y83N1eLFizVmzBiZpqk//OEPuvnmm7V161adf/75Z7RvaGjQddddp4yMDL322mvKycnR119/rbS0tGjVHxVJ4Z4RhmkAAIi1iMLIzJkzW71etGiRli5dqvXr17cZRl588UWdOHFCH330keLi4iRJI0eO7Hq1PSS06BnDNAAAxF6X54z4fD4tW7ZMNTU1KigoaLPNW2+9pYKCAi1YsECZmZmaOHGinnzySfl8Hf/oe71eeTyeVo+eRM8IAADWiahnRJK2b9+ugoIC1dfXKzk5WcuXL9eECRPabLt3716tXr1ac+bM0YoVK7Rnzx7dfffdamxs1GOPPdbudxQXF+vxxx+PtLQuSwju2lvDrr0AAMScYZqmGckbGhoadODAAVVVVem1117T73//e3344YdtBpKxY8eqvr5e+/btk90e+MF/+umn9dRTT6msrKzd7/B6vfJ6veHXHo9HeXl5qqqqktvtjqTcTvmfPcc05/cbNDYzWf/vvqui/vkAAAxEHo9HqampZ/39jrhnxOl0avTo0ZKkyZMna9OmTVqyZImeffbZM9pmZ2crLi4uHEQk6bzzzlN5ebkaGhrkdDrb/A6XyyWXyxVpaV0W3puGOSMAAMRct9cZ8fv9rXoxWpo2bZr27Nkjv98fPrZ7925lZ2e3G0SswARWAACsE1EYKSoq0po1a7R//35t375dRUVFKi0t1Zw5cyRJhYWFKioqCrefP3++Tpw4oYULF2r37t1655139OSTT2rBggXR/Vd0U6hnpIYVWAEAiLmIhmkqKipUWFiosrIypaamKj8/X6tWrdJ1110nSTpw4IBstuZ8k5eXp1WrVum+++5Tfn6+cnJytHDhQt1///3R/Vd0U1Jw115vk18+vym7zbC4IgAABo6IJ7BaobMTYLqqvtGn8Y+8K0na/vNvKyU+LurfAQDAQNPZ32/2ppHkctgU6gxh3ggAALFFGJFkGEZ4517mjQAAEFuEkSB27gUAwBqEkSBu7wUAwBqEkaDw7b3sTwMAQEwRRoJCc0bq6BkBACCmCCNBCSx8BgCAJQgjQUlMYAUAwBKEkaDQBFbmjAAAEFuEkaCk4DANc0YAAIgtwkhQQnjRM8IIAACxRBgJCvWM1DJMAwBATBFGghJdLHoGAIAVCCNBifSMAABgCcJIUHgFVuaMAAAQU4SRoNAKrLWNhBEAAGKJMBIUHqZhBVYAAGKKMBLEBFYAAKxBGAlKYtdeAAAsQRgJomcEAABrEEaCEuMCPSMNTX41+vwWVwMAwMBBGAlKDO7aK9E7AgBALBFGgpx2mxw2QxKb5QEAEEuEkSDDMJTAJFYAAGKOMNJCeOEzVmEFACBmCCMthOaN0DMCAEDsEEZaCPWMMGcEAIDYIYy0wJwRAABijzDSQlJ4fxp6RgAAiBXCSAvNq7DSMwIAQKwQRloIrcJaw5wRAABihjDSQhI9IwAAxBxhpIXE0JwRekYAAIgZwkgLiUxgBQAg5ggjLSQG1xnh1l4AAGKHMNJCkothGgAAYo0w0kKoZ4QJrAAAxA5hpAUmsAIAEHuEkRbCc0a89IwAABArhJEWUuIDYaS6njACAECsRBRGli5dqvz8fLndbrndbhUUFGjlypWdeu+yZctkGIZmzZrVlTpjIjUhTpJUWdco0zQtrgYAgIEhojCSm5urxYsXa8uWLdq8ebOuueYa3Xzzzfrss886fN/+/fv1T//0T7riiiu6VWxPG5TklCQ1NPlV3+i3uBoAAAaGiMLIzJkzNWPGDI0ZM0Zjx47VokWLlJycrPXr17f7Hp/Ppzlz5ujxxx/XOeec0+2Ce1KS0y6HzZAknaxtsLgaAAAGhi7PGfH5fFq2bJlqampUUFDQbrtf/OIXysjI0Lx58zr92V6vVx6Pp9UjFgzDUFpicKimtjEm3wkAwEDniPQN27dvV0FBgerr65WcnKzly5drwoQJbbZdu3atXnjhBW3bti2i7yguLtbjjz8eaWlRkZbo1LFTDaqso2cEAIBYiLhnZNy4cdq2bZs2bNig+fPna+7cudq5c+cZ7aqrq3Xbbbfp+eef15AhQyL6jqKiIlVVVYUfBw8ejLTMLktLoGcEAIBYirhnxOl0avTo0ZKkyZMna9OmTVqyZImeffbZVu2++uor7d+/XzNnzgwf8/sDk0IdDod27dqlc889t83vcLlccrlckZYWFQzTAAAQWxGHkdP5/X55vd4zjo8fP17bt29vdezhhx9WdXW1lixZory8vO5+dY9ISwzcUcMwDQAAsRFRGCkqKtKNN96o4cOHq7q6WiUlJSotLdWqVaskSYWFhcrJyVFxcbHi4+M1ceLEVu9PS0uTpDOO9yahYZoqekYAAIiJiMJIRUWFCgsLVVZWptTUVOXn52vVqlW67rrrJEkHDhyQzda3F3UNDdNway8AALERURh54YUXOjxfWlra4fmXX345kq+zRHiYhp4RAABiom93Y/SA8ATWOsIIAACxQBg5TVpCqGeEYRoAAGKBMHIabu0FACC2CCOnaTlMw869AAD0PMLIaUITWNm5FwCA2CCMnIadewEAiC3CyGkCO/dyey8AALFCGGlD87wRekYAAOhphJE2sHMvAACxQxhpA8M0AADEDmGkDQzTAAAQO4SRNjBMAwBA7BBG2jAoiSXhAQCIFcJIG1LpGQEAIGYII21g514AAGKHMNIGdu4FACB2CCNtYOdeAABihzDSBnbuBQAgdggjbWi5c29do8/iagAA6N8II21IctoVZw/s3MtQDQAAPYsw0gbDMJSawJLwAADEAmGkHc2TWLmjBgCAnkQYaccg1hoBACAmCCPtYJgGAIDYIIy0g517AQCIDcJIOwax8BkAADFBGGlHaK0RJrACANCzCCPtYOdeAABigzDSjkGJTGAFACAWCCPtYAIrAACxQRhpB8M0AADEBmGkHezcCwBAbBBG2jGInXsBAIgJwkg7Etm5FwCAmCCMtIOdewEAiA3CSAcGsXMvAAA9jjDSgTR27gUAoMcRRjrAMA0AAD2PMNKB0DDNSYZpAADoMYSRDoSGaaoYpgEAoMdEFEaWLl2q/Px8ud1uud1uFRQUaOXKle22f/7553XFFVdo0KBBGjRokKZPn66NGzd2u+hYYedeAAB6XkRhJDc3V4sXL9aWLVu0efNmXXPNNbr55pv12Weftdm+tLRUs2fP1gcffKB169YpLy9P3/72t3Xo0KGoFN/TwhNYmTMCAECPMcxurnWenp6up556SvPmzTtrW5/Pp0GDBuk//uM/VFhY2Onv8Hg8Sk1NVVVVldxud3fKjcg7n5ZpQcnHunRkul65qyBm3wsAQH/Q2d9vR1e/wOfz6dVXX1VNTY0KCjr3Q11bW6vGxkalp6d32M7r9crr9YZfezyerpbZLezcCwBAz4t4Auv27duVnJwsl8ulu+66S8uXL9eECRM69d77779fw4YN0/Tp0ztsV1xcrNTU1PAjLy8v0jKjgp17AQDoeRGHkXHjxmnbtm3asGGD5s+fr7lz52rnzp1nfd/ixYu1bNkyLV++XPHx8R22LSoqUlVVVfhx8ODBSMuMikFJzeuMsHMvAAA9I+JhGqfTqdGjR0uSJk+erE2bNmnJkiV69tln233Pv/3bv2nx4sX6y1/+ovz8/LN+h8vlksvlirS0qEsL9ow0+AI79yY6uzyqBQAA2tHtdUb8fn+r+R2n+9d//Vc98cQTevfdd3XxxRd39+tiip17AQDoeRH9X/2ioiLdeOONGj58uKqrq1VSUqLS0lKtWrVKklRYWKicnBwVFxdLkn75y1/q0UcfVUlJiUaOHKny8nJJUnJyspKTk6P8T4k+wzCUlujU0WqvTtY2aFhagtUlAQDQ70QURioqKlRYWKiysjKlpqYqPz9fq1at0nXXXSdJOnDggGy25s6WpUuXqqGhQT/4wQ9afc5jjz2mn//8592vPgbSEuJ0tNqrKnpGAADoERGFkRdeeKHD86Wlpa1e79+/P9J6eh127gUAoGexN81ZhJaEP1HDWiMAAPQEwshZDE0J3NVT4am3uBIAAPonwshZDEsNrIlyuIowAgBATyCMnEXoDpqyqjqLKwEAoH8ijJxFdmowjFTSMwIAQE8gjJzFsLTQME0dS8IDANADCCNnkRWcM1Lf6GcVVgAAegBh5CxcDruGJAdu7z3MvBEAAKKOMNIJoXkjh5k3AgBA1BFGOiE7OFTDHTUAAEQfYaQTQrf30jMCAED0EUY6gZ4RAAB6DmGkE7LTWGsEAICeQhjphOYl4ekZAQAg2ggjnRDqGTniqZffz8JnAABEE2GkEzJTXLIZUqPP1LFTXqvLAQCgXyGMdILDblNGCrv3AgDQEwgjnZQd3KOmrJJ5IwAARBNhpJOGhVZhpWcEAICoIox0Unj3XnpGAACIKsJIJ4X2p2HhMwAAoosw0knNPSMM0wAAEE2EkU6iZwQAgJ5BGOmk0N00FdVeNfr8FlcDAED/QRjppCFJLsXZDZlmYCVWAAAQHYSRTrLZDGWFd+8ljAAAEC2EkQiE5o1wey8AANFDGInAMHpGAACIOsJIBEK797IkPAAA0UMYiUCoZ4Ql4QEAiB7CSARYawQAgOgjjEQgm1VYAQCIOsJIBEI7956oaVB9o8/iagAA6B8IIxFIS4xTfFzgknFHDQAA0UEYiYBhGOHeEe6oAQAgOggjERoWvL2XO2oAAIgOwkiEskMLn9EzAgBAVBBGIpRNzwgAAFFFGIlQ85Lw9IwAABANhJEINS8JT88IAADREFEYWbp0qfLz8+V2u+V2u1VQUKCVK1d2+J5XX31V48ePV3x8vCZNmqQVK1Z0q2CrhZeEr6yTaZoWVwMAQN8XURjJzc3V4sWLtWXLFm3evFnXXHONbr75Zn322Wdttv/oo480e/ZszZs3T1u3btWsWbM0a9Ys7dixIyrFWyEvPVE2Q6r2Nqmi2mt1OQAA9HmG2c3/e5+enq6nnnpK8+bNO+Pc3/3d36mmpkZvv/12+Nhll12mb33rW3rmmWc6/R0ej0epqamqqqqS2+3uTrlRcc2vSrX3aI3+cMelumrsUKvLAQCgV+rs73eX54z4fD4tW7ZMNTU1KigoaLPNunXrNH369FbHrr/+eq1bt67Dz/Z6vfJ4PK0evcl5WYEL+kVZ76oLAIC+KOIwsn37diUnJ8vlcumuu+7S8uXLNWHChDbblpeXKzMzs9WxzMxMlZeXd/gdxcXFSk1NDT/y8vIiLbNHjctKkSTtKq+2uBIAAPq+iMPIuHHjtG3bNm3YsEHz58/X3LlztXPnzqgWVVRUpKqqqvDj4MGDUf387gqFkS8IIwAAdJsj0jc4nU6NHj1akjR58mRt2rRJS5Ys0bPPPntG26ysLB05cqTVsSNHjigrK6vD73C5XHK5XJGWFjOhYZo9FafU6PMrzs4d0gAAdFW3f0X9fr+83rbvKikoKND777/f6th7773X7hyTviJ3UIISnXY1+Pzaf6zG6nIAAOjTIuoZKSoq0o033qjhw4erurpaJSUlKi0t1apVqyRJhYWFysnJUXFxsSRp4cKFuuqqq/SrX/1KN910k5YtW6bNmzfrueeei/6/JIZsNkPjslK09UClPi+v1pjMFKtLAgCgz4qoZ6SiokKFhYUaN26crr32Wm3atEmrVq3SddddJ0k6cOCAysrKwu2nTp2qkpISPffcc7rgggv02muv6Y033tDEiROj+6+wwPjwJFbuqAEAoDsi6hl54YUXOjxfWlp6xrFbbrlFt9xyS0RF9QXjMrmjBgCAaGDmZReNzw5MYv28jDACAEB3EEa6KDRMc6iyTp76RourAQCg7yKMdFFaolOZ7sDtx7sZqgEAoMsII90wPrQsPGEEAIAuI4x0w3iWhQcAoNsII90wPju0LDy39wIA0FWEkW4Yl9k8TGOapsXVAADQNxFGuuHcjCTZbYaq65tUVlVvdTkAAPRJhJFucDnsOndokiSGagAA6CrCSDeN444aAAC6hTDSTaE7ar5gJVYAALqEMNJN3N4LAED3EEa6aVwwjHx19JQamvwWVwMAQN9DGOmmnLQEpbgcavKb+uroKavLAQCgzyGMdJNhGOHeEYZqAACIHGEkCkIrse44VGVxJQAA9D2EkSi4aPggSdKm/ScsrgQAgL6HMBIFU84ZLEnacdijU94mi6sBAKBvIYxEQU5agnIHJcjnN7WZ3hEAACJCGImSKaMCvSMb9hFGAACIBGEkSqacky5J2rD3uMWVAADQtxBGouSyYM/Ip99UqbaBeSMAAHQWYSRK8tITlJ0arya/qY+/rrS6HAAA+gzCSJQYhqEpo4JDNfsYqgEAoLMII1EUusWXSawAAHQeYSSKQj0j2w5Wqr7RZ3E1AAD0DYSRKBo1JElDU1xqaPJr28FKq8sBAKBPIIxEUat5I3sZqgEAoDMII1HWPG+ESawAAHQGYSTKQj0jHx84qYYmv8XVAADQ+xFGomxMRrLSk5yqb/Tr028qrS4HAIBejzASZYZh6NKRofVGmDcCAMDZEEZ6QGifmvXsUwMAwFkRRnpAaAffLV+fVKOPeSMAAHSEMNIDxmelaHCSU7UNPq37it4RAAA6QhjpATaboesnZkmSVmwvs7gaAAB6N8JID/mbSdmSpHc/K2eoBgCADhBGesilo9I1JNmpytpGhmoAAOgAYaSHOOw2XX9+YKjmnU8ZqgEAoD2EkR50U35gqGbVToZqAABoT0RhpLi4WJdccolSUlKUkZGhWbNmadeuXWd9369//WuNGzdOCQkJysvL03333af6+vouF91XTBk1ODxU8xFDNQAAtCmiMPLhhx9qwYIFWr9+vd577z01Njbq29/+tmpqatp9T0lJiR544AE99thj+vzzz/XCCy/ov/7rv/Tggw92u/jezm4zdEPorhqGagAAaJMjksbvvvtuq9cvv/yyMjIytGXLFl155ZVtvuejjz7StGnTdOutt0qSRo4cqdmzZ2vDhg1dLLlvmTEpW39cf0Crdpbr//NNVJydkTEAAFrq1i9jVVWVJCk9Pb3dNlOnTtWWLVu0ceNGSdLevXu1YsUKzZgxo933eL1eeTyeVo++iqEaAAA61uUw4vf7de+992ratGmaOHFiu+1uvfVW/eIXv9Dll1+uuLg4nXvuubr66qs7HKYpLi5Wampq+JGXl9fVMi3XcqjmnU8PW1wNAAC9T5fDyIIFC7Rjxw4tW7asw3alpaV68skn9bvf/U4ff/yxXn/9db3zzjt64okn2n1PUVGRqqqqwo+DBw92tcxe4aZJwyRJqz47wl01AACcJqI5IyH33HOP3n77ba1Zs0a5ubkdtn3kkUd022236cc//rEkadKkSaqpqdGdd96phx56SDbbmXnI5XLJ5XJ1pbReKbAAmkvHTnn1P3uO6epxGVaXBABArxFRz4hpmrrnnnu0fPlyrV69WqNGjTrre2pra88IHHa7Pfx5A4HdZujG4FDNG1sPWVwNAAC9S0RhZMGCBfrjH/+okpISpaSkqLy8XOXl5aqrqwu3KSwsVFFRUfj1zJkztXTpUi1btkz79u3Te++9p0ceeUQzZ84Mh5KB4AeTAz1Ib39apvKq/r/GCgAAnRXRMM3SpUslSVdffXWr4y+99JJuv/12SdKBAwda9YQ8/PDDMgxDDz/8sA4dOqShQ4dq5syZWrRoUfcq72MuyEvTpSPTtXH/Cb380X49cON4q0sCAKBXMMw+MFbi8XiUmpqqqqoqud1uq8vpsvd2HtFP/s9mueMd+qjoWiW7ujRlBwCAPqGzv9+swBVD147P0DlDkuSpb9Irm/r2HUIAAEQLYSSGbDZDd1wemPT74v/sUxO3+QIAQBiJte9flKv0JKe+OVmnVZ8dsbocAAAsRxiJsQSnXT+6bIQk6bm/7h0wtzcDANAewogFCgtGyOmw6ZODldr89UmrywEAwFKEEQsMSXbp+xflSJKeX7PX4moAALAWYcQi8y4/R5L03udHtKu82uJqAACwDmHEIqMzkjVjUpZMU/r5W58xdwQAMGARRiz04Izz5HLYtG7vcb2zvczqcgAAsARhxEK5gxJ199WjJUmL3vlctQ1NFlcEAEDsEUYs9g9XnaPcQQkqq6rXbz/YY3U5AADEHGHEYvFxdj36NxMkSc+v2ad9x2osrggAgNgijPQC103I1JVjh6rB59cv/vyZ1eUAABBThJFewDAMPTZzguLshj7YdVR/2cky8QCAgYMw0kucOzQ5vIneQ29s1/FTXosrAgAgNggjvcjCa8fo3KFJOuLx6r5XPpHfz9ojAID+jzDSiyQ6HfrtnIvkcti0ZvdRPbPmK6tLAgCgxxFGepnxWW794ubzJUm/+n+7tWn/CYsrAgCgZxFGeqG/vThPs741TD6/qZ+WbNWJmgarSwIAoMcQRnohwzC06LuTdM7QJJV76vW/X9nG/BEAQL9FGOmlklwO/fbWwPyRD3Yd1ZMrPmczPQBAv0QY6cXOy3Zr8fcnSZJ+v3afnl2z1+KKAACIPsJIL/fdC3P14IzxkqTFK7/QK5sPWlwRAADRRRjpA+688lz9w5XnSJKKXt+u91ihFQDQjxBG+ogHbhyvH0zOlc9v6p6Sj7VxH7f8AgD6B8JIH2EYhhZ/b5KuHZ8hb5Nft7+0UX/98qjVZQEA0G2EkT7EYbfpP269SJePHqLaBp/ueHmTVmwvs7osAAC6hTDSxyQ47Xrh9os1Y1KWGn2mFpR8rJINB6wuCwCALiOM9EEuh12/mX2Rbp0yXKYpPbh8u377wR7WIQEA9EmEkT7KbjO0aNZELfhf50qSnlq1S/f/96eqb/RZXBkAAJEhjPRhhmHon68fr0f+ZoJshvTK5m/0t8+u06HKOqtLAwCg0wgj/cC8y0fpD3dcqrTEOH36TZVm/matPvrqmNVlAQDQKYSRfuKKMUP153su1/nD3DpR06Af/X6DnvnwKzbYAwD0eoSRfiQvPVH/PX+qvndRjvxmYPn42c+v18ETtVaXBgBAuwgj/Ux8nF2/uuUCLf7eJCU67dqw74Ru+PUa/demA9xtAwDolQgj/ZBhGPrhpcO1cuEVumTkINU0+HT/f2/Xj/+wWUc89VaXBwBAK4SRfmzE4CQtu7NARTeOl9Nu0/tfVOiafyvV82v2qtHnt7o8AAAkEUb6PbvN0D9cda7e+uk0XTg8TTUNPi1a8blmLPmr1n113OryAACQYfaBiQQej0epqamqqqqS2+22upw+y+839dqWb7T43S90oqZBkjTzgmH652+P0/DBiRZXBwDobzr7+x1Rz0hxcbEuueQSpaSkKCMjQ7NmzdKuXbvO+r7KykotWLBA2dnZcrlcGjt2rFasWBHJVyMKbDZDf3tJnlb/76s0Z8pwGYb0508O69qnS/XomztUUc18EgBA7EXUM3LDDTfohz/8oS655BI1NTXpwQcf1I4dO7Rz504lJSW1+Z6GhgZNmzZNGRkZevDBB5WTk6Ovv/5aaWlpuuCCCzr1vfSM9Iwdh6r0y3e/0F+/DCyQlhBn17zLR+knV5yj1MQ4i6sDAPR1nf397tYwzdGjR5WRkaEPP/xQV155ZZttnnnmGT311FP64osvFBfXtR84wkjP+mjPMf1y1S59crBSkpTscmjOlOGad/koZbjjrS0OANBn9cgwzemqqqokSenp6e22eeutt1RQUKAFCxYoMzNTEydO1JNPPimfjw3deoupo4fojbun6tnbJmt8VopOeZv07Jq9uvyXH6jo9e3af6zG6hIBAP1Yl3tG/H6/vvOd76iyslJr165tt9348eO1f/9+zZkzR3fffbf27Nmju+++Wz/72c/02GOPtfker9crr9cbfu3xeJSXl0fPSAyYpqnVX1Tod6VfacvXJyVJhiH9r3EZuq1ghK4aM1Q2m2FxlQCAvqDHh2nmz5+vlStXau3atcrNzW233dixY1VfX699+/bJbrdLkp5++mk99dRTKisra/M9P//5z/X444+fcZwwElsb953Q0tI9+mDX0fCxEYMTddtlI/SDyblKS3RaWB0AoLfr0TByzz336M0339SaNWs0atSoDtteddVViouL01/+8pfwsZUrV2rGjBnyer1yOs/8QaNnpHfZe/SU/rj+gF7dclDV9U2SJKfdpukTMvSDybm6csxQOewsWQMAaK2zYcQRyYeapqmf/vSnWr58uUpLS88aRCRp2rRpKikpkd/vl80W+MHavXu3srOz2wwikuRyueRyuSIpDT3onKHJenTmBP3T9WP1xtbD+uP6r7WzzKMV28u1Ynu5hqa49N0LczQzf5gm5rhlGAzjAAA6L6KekbvvvlslJSV68803NW7cuPDx1NRUJSQkSJIKCwuVk5Oj4uJiSdLBgwd1/vnna+7cufrpT3+qL7/8UnfccYd+9rOf6aGHHurU93I3Te/z2eEq/feWQ3pj26HwAmqSNDw9UTflZ+tv8rM1IZtgAgADWY8M07T3w/LSSy/p9ttvlyRdffXVGjlypF5++eXw+XXr1um+++7Ttm3blJOTo3nz5un+++8PzyGJ1j8GsdfQ5NcHuyr01ieHtfrzCtU1Nt8lNTw9UdPPy9T0CRm6ZGS64hjKAYABJSbrjMQKYaRvqG1o0uovKvTOp2Va/UWFvE3Nm/G54x26elyGrho7VFeMHaKMFNYvAYD+jjACS9V4m7R2zzH9ZecRrf6iQsdbDOVI0visFF01dqguHzNEk0cMUqIzoulLAIA+gDCCXsPnN7Xt4Em9/3mF/vrlMW0/VNXqfJzd0AW5abrsnMG67JzBunB4mpJchBMA6OsII+i1jp/yau2eY1qz+5jWfXVMh6tab9Bntxk6LztFF49I1+QRgzR5xCBlp8YzGRYA+hjCCPoE0zR18ESd1u89rvV7j2vDvhM6VFl3RruhKS5dkJumb+Wl6oK8NE0clqpBSSy6BgC9GWEEfVZZVZ027z+pLV+f1OavT+jzsmr5/Gf+zzQnLUHnD3Pr/GGpOn+YW+cNc2sYPSgA0GsQRtBv1DX4tLOsStsOVumTg5X65JtKfX28ts22KfEOnZfl1risFI3NStHYjGSNyUxROr0oABBzhBH0a576Ru087NGOQ1X67LBHn5d5tKfilJra6EGRpCHJTo3OSNa5Q5N1ztBknTs0SecOTdawtATZ2fgPAHoEYQQDTkOTX18dPaVd5dX6vNyjL4+c0u4j1frm5JlzUEKcDpuGpydq5OAkjRqSqBGDkzRicKKGpydqWFoCC7UBQDcQRoCgGm+Tvjp6Sl8eOaW9x05p79EafXX0lPYfq1WDz9/u++w2QzlpCcpLT1BuWqJyByUoLz1ROYMSlJOWoIwUFxsEAkAHemSjPKAvSnI5lJ+bpvzctFbHfX5ThyvrtP94jfYfq9G+Y7X6+niNDpyo1YETtfI2+cPPpeNnfK7dZijLHa+ctAQNS4tXVmqCslPjg48EZaa6NCTJJRvDQADQIcIIBiy7zVBeeqLy0hN1xZihrc75/aaOnvLq6+O1+uZkrQ6eqAv8PVmrb07WqbyqXk1+U4cq69q8FTnEYTOUkeJSZmq8MlPileF2KSPFpQx3fOBvSryGpriUnuRk7gqAAYswArTBZjOU6Y5Xpjtel45KP+O8z2/qaLU3HEbKKutUVlWv8qp6lVUFnh895VWT39ThqvozFnY74/sMaXCyS0OSXRqS7Gz1d3CyS4OTnBqc7FR6UuBYfFznNpkEgL6AMAJ0gd1mKCs1Xlmp8Zo8YlCbbZp8fh095VV5Vb2OeOp1xONVRXW9KjxeHan2qsJTr2OnvDpe0yC/KR2t9upotbdT358QZ1d6UiCcDEpyKj0xToOSnBqU6NSgxDilJQaepyXGKS0xToMSnUp02lmDBUCvRBgBeojDblN2aoKyUxM6bNfk8+tEbUM4jBw71aBjp7w6Vu0Nh5UTNQ06fqpBx2u8avSZqmv0nXWI6HRxdkOpCU6lJjiUluhUWkKcUhPi5A4+UhPi5I53NB+Lj5M7waGU+DiluBzMfQHQYwgjgMUcdpsyUuKVkRJ/1ramaara26STwYByoqZBx2saVFnboJO1jTpZ06CTwedVtY06WdugytpGNfj8avSZgZBzyiupJuI6U1wOpcQHw0m8Q8nB58kuh9zxDiW7AseSg+2SXIFHiqv5ebLLwdwYAGcgjAB9iGEYgR6L+DiNGJzUqfeYZqAnpbK2UVV1jcG/DeHXnvrA36q6JlXVNaq6vlGeukZ56gOvG5oCtz9Xe5tU7W2SzjL/5Wzi42xKDgUUp0NJLrsSnYGgkui0Kyn4N/AIPnc5lBhnV6Kr+VhCnF0JwXbxDjs9N0AfRhgB+jnDMII/4A4NS+t4yKgt3iafquubVF3fJE9do6rrm3TKGwgrgeONqvE26ZS3SZ76Jp2qDzyv8QbO1zQEjoVWx61v9Ku+sUHHTjVE9d8ZH2dTotMRDikJcYFHvNOuhDhb+LjLEfgb77ArwWlTfJy9+eFo+Tr43BF47oqzy+WwyeWwMfcGiDLCCIAOuRx2uZLtGpLs6vJnmKapBp9fNV6faryBgBIIMD7VepvDS22jT7Ven2oamsJ/6xp8qm3wBc81qbbBp7pGn2obmlTf2LxoXSjk9DTDUDCUBMJJfCikxDUfC5+Ps8lpbz7nbHHO6bC1eB1oFzrW8nngXKB9nN1o1YZQhP6CMAKgxxmGEfyhtkd100K/PzAEVdfoU104pASCirfRHz5e2+iTN/i8vsmnuobAOW/wvfXhv37VN/rkbQr8rQ8da/IptFa1aYaCT/ur98ZKnN2Q025TnMOmOHtziAmFljh78/E4uxF47TjtdfA9DlvodeCvw26T027IYbe1Pm4LnW9u77A1t3Gc3sZmk91uhI8xZwhtIYwA6LNsNiM8ObYnmaapRp+p+iafvC0Ci7cpEFa8TcHXoeeNfnl9fjU0Nb9u8DWfDxxvPt8QbBs+3uJ1y+enbwTZ6DPV6PNJDb4e/fdHk2FIcbZAULHbWgccu82QIxhcHME2LZ/bW7aztf068DcQjFq+drR6Hfhra3m+1evTzwdqsNsku80muxE41vLRsr3t9POGIZtNcthsshmiR6sNhBEAOAvDMOR0BHobdPabnnqM3x8Y7mrw+dXYIqg0+vxqaDIDf1ucC4SV5lDTGDzX6DObX/v8avKZ8jb51eQPPA+/N3is0WcG/jaZagy2aQy/31STz69Gf+Bvk6+5TVu7aJumgv8GCy5gL2EzgsHEpmBQaQ49oSDTMtDYDLVxrDnoGMHzZ75fsgU/PxSgDCP4naHjwRoMw9C8y0cpLz3RkmtCGAGAPsJmMxRvs/eZFXhNMxBIGn2BXp2mFsHF1yq0NIeXplDbFs99oc/wmfKZgddNLT/Tb8rnP/O1zy/5/IHv8/vNVp/lNwNtfaHv8vvl85vy+xWoJ9g2/DBPe+1vfq8/eL7lezriDwYy9bJA9p1vDSOMAAD6F8MwwnNNBhr/6QHGDAQwn9kivPhM+U9vEwxE4efhY+ZpxxR+7j/teKitP/RdflM+s3VNZugzzNBzU1lu67r9CCMAAESZzWbIJkN9pBPLcgMvrgIAgF6FMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApfrErr2maUqSPB6PxZUAAIDOCv1uh37H29Mnwkh1dbUkKS8vz+JKAABApKqrq5WamtruecM8W1zpBfx+vw4fPqyUlBQZhhG1z/V4PMrLy9PBgwfldruj9rk4E9c6drjWscX1jh2udexE61qbpqnq6moNGzZMNlv7M0P6RM+IzWZTbm5uj32+2+3mf9gxwrWOHa51bHG9Y4drHTvRuNYd9YiEMIEVAABYijACAAAsNaDDiMvl0mOPPSaXy2V1Kf0e1zp2uNaxxfWOHa517MT6WveJCawAAKD/GtA9IwAAwHqEEQAAYCnCCAAAsBRhBAAAWGpAh5Hf/va3GjlypOLj4zVlyhRt3LjR6pL6vOLiYl1yySVKSUlRRkaGZs2apV27drVqU19frwULFmjw4MFKTk7W97//fR05csSiivuHxYsXyzAM3XvvveFjXOfoOnTokH70ox9p8ODBSkhI0KRJk7R58+bwedM09eijjyo7O1sJCQmaPn26vvzySwsr7pt8Pp8eeeQRjRo1SgkJCTr33HP1xBNPtNrbhGvdNWvWrNHMmTM1bNgwGYahN954o9X5zlzXEydOaM6cOXK73UpLS9O8efN06tSp7hdnDlDLli0znU6n+eKLL5qfffaZ+ZOf/MRMS0szjxw5YnVpfdr1119vvvTSS+aOHTvMbdu2mTNmzDCHDx9unjp1KtzmrrvuMvPy8sz333/f3Lx5s3nZZZeZU6dOtbDqvm3jxo3myJEjzfz8fHPhwoXh41zn6Dlx4oQ5YsQI8/bbbzc3bNhg7t2711y1apW5Z8+ecJvFixebqamp5htvvGF+8skn5ne+8x1z1KhRZl1dnYWV9z2LFi0yBw8ebL799tvmvn37zFdffdVMTk42lyxZEm7Dte6aFStWmA899JD5+uuvm5LM5cuXtzrfmet6ww03mBdccIG5fv16869//as5evRoc/bs2d2ubcCGkUsvvdRcsGBB+LXP5zOHDRtmFhcXW1hV/1NRUWFKMj/88EPTNE2zsrLSjIuLM1999dVwm88//9yUZK5bt86qMvus6upqc8yYMeZ7771nXnXVVeEwwnWOrvvvv9+8/PLL2z3v9/vNrKws86mnngofq6ysNF0ul/mf//mfsSix37jpppvMO+64o9Wx733ve+acOXNM0+RaR8vpYaQz13Xnzp2mJHPTpk3hNitXrjQNwzAPHTrUrXoG5DBNQ0ODtmzZounTp4eP2Ww2TZ8+XevWrbOwsv6nqqpKkpSeni5J2rJlixobG1td+/Hjx2v48OFc+y5YsGCBbrrpplbXU+I6R9tbb72liy++WLfccosyMjJ04YUX6vnnnw+f37dvn8rLy1td79TUVE2ZMoXrHaGpU6fq/fff1+7duyVJn3zyidauXasbb7xREte6p3Tmuq5bt05paWm6+OKLw22mT58um82mDRs2dOv7+8RGedF27Ngx+Xw+ZWZmtjqemZmpL774wqKq+h+/3697771X06ZN08SJEyVJ5eXlcjqdSktLa9U2MzNT5eXlFlTZdy1btkwff/yxNm3adMY5rnN07d27V0uXLtU//uM/6sEHH9SmTZv0s5/9TE6nU3Pnzg1f07b+m8L1jswDDzwgj8ej8ePHy263y+fzadGiRZozZ44kca17SGeua3l5uTIyMlqddzgcSk9P7/a1H5BhBLGxYMEC7dixQ2vXrrW6lH7n4MGDWrhwod577z3Fx8dbXU6/5/f7dfHFF+vJJ5+UJF144YXasWOHnnnmGc2dO9fi6vqXV155RX/6059UUlKi888/X9u2bdO9996rYcOGca37sQE5TDNkyBDZ7fYz7iw4cuSIsrKyLKqqf7nnnnv09ttv64MPPlBubm74eFZWlhoaGlRZWdmqPdc+Mlu2bFFFRYUuuugiORwOORwOffjhh/r3f/93ORwOZWZmcp2jKDs7WxMmTGh17LzzztOBAwckKXxN+W9K9/3zP/+zHnjgAf3whz/UpEmTdNttt+m+++5TcXGxJK51T+nMdc3KylJFRUWr801NTTpx4kS3r/2ADCNOp1OTJ0/W+++/Hz7m9/v1/vvvq6CgwMLK+j7TNHXPPfdo+fLlWr16tUaNGtXq/OTJkxUXF9fq2u/atUsHDhzg2kfg2muv1fbt27Vt27bw4+KLL9acOXPCz7nO0TNt2rQzblHfvXu3RowYIUkaNWqUsrKyWl1vj8ejDRs2cL0jVFtbK5ut9U+T3W6X3++XxLXuKZ25rgUFBaqsrNSWLVvCbVavXi2/368pU6Z0r4BuTX/tw5YtW2a6XC7z5ZdfNnfu3GneeeedZlpamlleXm51aX3a/PnzzdTUVLO0tNQsKysLP2pra8Nt7rrrLnP48OHm6tWrzc2bN5sFBQVmQUGBhVX3Dy3vpjFNrnM0bdy40XQ4HOaiRYvML7/80vzTn/5kJiYmmn/84x/DbRYvXmympaWZb775pvnpp5+aN998M7ebdsHcuXPNnJyc8K29r7/+ujlkyBDzX/7lX8JtuNZdU11dbW7dutXcunWrKcl8+umnza1bt5pff/21aZqdu6433HCDeeGFF5obNmww165da44ZM4Zbe7vrN7/5jTl8+HDT6XSal156qbl+/XqrS+rzJLX5eOmll8Jt6urqzLvvvtscNGiQmZiYaH73u981y8rKrCu6nzg9jHCdo+vPf/6zOXHiRNPlcpnjx483n3vuuVbn/X6/+cgjj5iZmZmmy+Uyr732WnPXrl0WVdt3eTwec+HChebw4cPN+Ph485xzzjEfeugh0+v1httwrbvmgw8+aPO/z3PnzjVNs3PX9fjx4+bs2bPN5ORk0+12m3//939vVldXd7s2wzRbLGsHAAAQYwNyzggAAOg9CCMAAMBShBEAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsNT/D4jPIDWxn8z7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this gets quite close to the manual approach before, this time with gradient based learning\n",
    "- makes sense that it's not better because there is no additional information\n",
    "- easier here to keep them in a table, gradient based is much more flexible in how it can be expanded\n",
    "\n",
    "- only thing that will fundamentally change is how we get logits. we can in more information here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eenanei.\n",
      "haiaviamethaie.\n",
      "bearunnde.\n",
      "cyr.\n",
      "iaicarimiten.\n",
      "jos.\n",
      "shan.\n",
      "styrjan.\n",
      "kaiet.\n",
      "krarincoahl.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        x_enc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = x_enc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "        out.append(idx2char[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(\"\".join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
